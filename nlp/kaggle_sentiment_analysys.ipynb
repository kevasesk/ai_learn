{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62fc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 21:18:21.190710: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749493101.236800   44913 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749493101.250763   44913 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749493101.287015   44913 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749493101.287055   44913 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749493101.287061   44913 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749493101.287065   44913 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-09 21:18:21.298302: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9110e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n",
      "Path to dataset files: /home/eugen/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f83764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              review  \\\n",
       " 0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.   \n",
       " 1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.   \n",
       " 2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.   \n",
       " \n",
       "   sentiment  \n",
       " 0  positive  \n",
       " 1  positive  \n",
       " 2  positive  ,\n",
       " None,\n",
       " review       0\n",
       " sentiment    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(path + '/IMDB Dataset.csv')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "dataset.head(3), dataset.info(), dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423b337c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14105</th>\n",
       "      <td>i had high hopes for it when i heard that it was being made back in  because i read the devil and daniel webster when i was a kid and i found it very interesting they made some changes to the story that dont make much sense to me daniel webster in the story was a famous lawyer from new hampshire in the story in the movie he is an editor a lawyer makes more sense since he ends up representing jabez stone against the devil himherself he was a man in the story but was a woman in the movie in a trial where both of their souls are on the line as an editor it doesnt seem likely that daniel webster would have the skill to do thisbr br the acting was decent by all except for alec baldwin and dan aykroyd these are two actors that i like they just did an awful job in this movie it was as though they thought they were acting in a comedy but the movie was more a serious one than a comedy this might be partly due to the fact that the movie was filmed with a particular vision in mind and was then reedited by somebody else given this fact its surprising that it was at all coherent i was surprised to see a fair amount of snl cast members in the movie which further leads me to believe it may have originally been filmed with the intention of it being more of a comedybr br all in all i would have to say it wasnt completely awful but it wasnt much good if i could get the hour and a half back and do something else with it i would the ending was especially disappointing as in the original story daniel webster defeats the devil in the trial jabez then starts out again at the beginning of the movieliterally we are just brought back to the first scene with jabez and then the movie abruptly ends it actually looked as though they just replayed jabez first scene over and called it the end there is no indication that jabez has the benefit of any of the knowledge or experience he gained so who is to say he didnt just repeat his mistakes over again and perhaps over and over in an endless loop it was an extremely disappointing end and did not make a lot of sense the decent cast and the acting of everyone except for baldwin and aykroyd are the only things that keep this from being a complete and total crap sandwich</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33617</th>\n",
       "      <td>warning slight plot spoilers aheadbr br the italian job is not the best movie youll see all year or probably even this summer but it is a worthwhile two hours because it colors within the lines knowing its limits and not attempting to exceed thembr br what carries the movie is the work of the cast in a movie about a crew of thieves the individuals must have a good rapport with each other without that cohesive feel the audience doesnt believe in the characters collectively or individually and the movie never has a chance but from the first scenes in which the men joke around and rag on each other while infiltrating a venetian palace the proper chemistry is in placebr br the characters themselves arent anything novel theyre your basic gang of criminals containing about half a dozen players each with a specific and defining skill but each actor brings the proper goods to the table for his or her part mark wahlbergs understated acting and humor fits well with his part as the mastermind planner edward norton provides attitude and twirls his mustache well in his dark role donald sutherland is the father figure of the crew and he looks the part of the suave and oldfashioned thief who is still mentally spry jason statham seth green and mos def dont do much beyond their characters abilities but they each nail those parts statham as the smoothoperating driver green as the tech whiz geek with a chip on his shoulder and def as the demolitions man charlize theron slides in well in a part that doesnt ask too much of her she is primarily asked to to drive fast and look good that she does none of the characters are that deep or threedimensional but in this familiar sort of movie two dimensions are all that is required br br as the title implies the movie has a european feel to it a la the bourne identity in part because it was shot on location in venice along with philadelphia and los angeles also contributing to the euro flair is the rhythmic bouncy music which adds to the upbeat nature of the flick and complements the rapport of the cast the look of the movie is also a perfect match the bright colors of all locales enhance the mood and add to the attitude the minis not only provide a fun variation on the car chase but also work as a necessary plot device br br the plot is more or less straightforward there are a few surprises but they are more of the swiftandsmoothturn variety as opposed to the dropyourjaw hairpin curve even with those the movie speeds along once the foundation is laid by the first act everything continuously progresses thankfully there are no breaks in the action for a romance something the movie wisely avoided there arent even any breaks for real life the story has its purpose and runs that course without distractions the lack of character depth prevents the italian job from being more than a good popcorn movie but with all the complex details of the heistplanning such superfluities would have dragged down the pace and quality of the flickbr br there are a number of implausibilities that i thought of both during and after viewing but the movie is so enjoyable that i didnt and dont care in the real world most of the movie probably couldnt have gone off that cleanly but the italian job doesnt take place in the real world it occurs in a stylish and lighthearted criminal world that appeals to the rebel in all of us br br the italian job is a movie in the true sense of the word it has no pretenses of oscar and contains no deep moral message it provides pure escapism entertainment and does so quite wellbr br bottom line maybe the best popcorn movie of the year so far  of</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>if you only read a synopsis of the plot this movie would sound like quite a typical one of the s the story would seem quite contrived the subject matter maudlin the strength and beauty of this film is in the direct earthy performances of the casti have seldom seen jean harlow display such a range of feeling rich and subtle nuances float over her face if you watch their faces during the wedding ceremony in the chapel there is such an obvious depth of feeling between the principal characters the raw emotions are so sincerely portrayed so true the final sequence is almost unbearably poignant when clark gable looks down with such joy and surprise at his son lifts him up and proudly says my kid i couldnt help remember that mr gables own son was born to him posthumously this is one of the finest examples of depression era cinema</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      review  \\\n",
       "14105                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          i had high hopes for it when i heard that it was being made back in  because i read the devil and daniel webster when i was a kid and i found it very interesting they made some changes to the story that dont make much sense to me daniel webster in the story was a famous lawyer from new hampshire in the story in the movie he is an editor a lawyer makes more sense since he ends up representing jabez stone against the devil himherself he was a man in the story but was a woman in the movie in a trial where both of their souls are on the line as an editor it doesnt seem likely that daniel webster would have the skill to do thisbr br the acting was decent by all except for alec baldwin and dan aykroyd these are two actors that i like they just did an awful job in this movie it was as though they thought they were acting in a comedy but the movie was more a serious one than a comedy this might be partly due to the fact that the movie was filmed with a particular vision in mind and was then reedited by somebody else given this fact its surprising that it was at all coherent i was surprised to see a fair amount of snl cast members in the movie which further leads me to believe it may have originally been filmed with the intention of it being more of a comedybr br all in all i would have to say it wasnt completely awful but it wasnt much good if i could get the hour and a half back and do something else with it i would the ending was especially disappointing as in the original story daniel webster defeats the devil in the trial jabez then starts out again at the beginning of the movieliterally we are just brought back to the first scene with jabez and then the movie abruptly ends it actually looked as though they just replayed jabez first scene over and called it the end there is no indication that jabez has the benefit of any of the knowledge or experience he gained so who is to say he didnt just repeat his mistakes over again and perhaps over and over in an endless loop it was an extremely disappointing end and did not make a lot of sense the decent cast and the acting of everyone except for baldwin and aykroyd are the only things that keep this from being a complete and total crap sandwich   \n",
       "33617  warning slight plot spoilers aheadbr br the italian job is not the best movie youll see all year or probably even this summer but it is a worthwhile two hours because it colors within the lines knowing its limits and not attempting to exceed thembr br what carries the movie is the work of the cast in a movie about a crew of thieves the individuals must have a good rapport with each other without that cohesive feel the audience doesnt believe in the characters collectively or individually and the movie never has a chance but from the first scenes in which the men joke around and rag on each other while infiltrating a venetian palace the proper chemistry is in placebr br the characters themselves arent anything novel theyre your basic gang of criminals containing about half a dozen players each with a specific and defining skill but each actor brings the proper goods to the table for his or her part mark wahlbergs understated acting and humor fits well with his part as the mastermind planner edward norton provides attitude and twirls his mustache well in his dark role donald sutherland is the father figure of the crew and he looks the part of the suave and oldfashioned thief who is still mentally spry jason statham seth green and mos def dont do much beyond their characters abilities but they each nail those parts statham as the smoothoperating driver green as the tech whiz geek with a chip on his shoulder and def as the demolitions man charlize theron slides in well in a part that doesnt ask too much of her she is primarily asked to to drive fast and look good that she does none of the characters are that deep or threedimensional but in this familiar sort of movie two dimensions are all that is required br br as the title implies the movie has a european feel to it a la the bourne identity in part because it was shot on location in venice along with philadelphia and los angeles also contributing to the euro flair is the rhythmic bouncy music which adds to the upbeat nature of the flick and complements the rapport of the cast the look of the movie is also a perfect match the bright colors of all locales enhance the mood and add to the attitude the minis not only provide a fun variation on the car chase but also work as a necessary plot device br br the plot is more or less straightforward there are a few surprises but they are more of the swiftandsmoothturn variety as opposed to the dropyourjaw hairpin curve even with those the movie speeds along once the foundation is laid by the first act everything continuously progresses thankfully there are no breaks in the action for a romance something the movie wisely avoided there arent even any breaks for real life the story has its purpose and runs that course without distractions the lack of character depth prevents the italian job from being more than a good popcorn movie but with all the complex details of the heistplanning such superfluities would have dragged down the pace and quality of the flickbr br there are a number of implausibilities that i thought of both during and after viewing but the movie is so enjoyable that i didnt and dont care in the real world most of the movie probably couldnt have gone off that cleanly but the italian job doesnt take place in the real world it occurs in a stylish and lighthearted criminal world that appeals to the rebel in all of us br br the italian job is a movie in the true sense of the word it has no pretenses of oscar and contains no deep moral message it provides pure escapism entertainment and does so quite wellbr br bottom line maybe the best popcorn movie of the year so far  of    \n",
       "6473                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      if you only read a synopsis of the plot this movie would sound like quite a typical one of the s the story would seem quite contrived the subject matter maudlin the strength and beauty of this film is in the direct earthy performances of the casti have seldom seen jean harlow display such a range of feeling rich and subtle nuances float over her face if you watch their faces during the wedding ceremony in the chapel there is such an obvious depth of feeling between the principal characters the raw emotions are so sincerely portrayed so true the final sequence is almost unbearably poignant when clark gable looks down with such joy and surprise at his son lifts him up and proudly says my kid i couldnt help remember that mr gables own son was born to him posthumously this is one of the finest examples of depression era cinema   \n",
       "\n",
       "      sentiment  \n",
       "14105  negative  \n",
       "33617  positive  \n",
       "6473   positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.sample(n=2000)\n",
    "dataset['review'] = dataset['review'].apply(lambda row: row.lower())\n",
    "dataset['review'] = dataset['review'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "dataset.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa670e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d59ba68af024476b3d6a1b8066bde8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6b33a53841406c9285a93762b2aba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[  101,  6511,  7380, ...,  4038,  1998,   102],\n",
       "       [  101,  2021,  1996, ..., 28667, 18557,   102],\n",
       "       [  101,  1045,  2245, ...,  2003,  8857,   102],\n",
       "       ...,\n",
       "       [  101,  1045, 12246, ..., 26749,  2024,   102],\n",
       "       [  101,  2065,  2412, ...,  4121, 20014,   102],\n",
       "       [  101,  6195,  2035, ...,  2054,  2500,   102]], shape=(2000, 50)), 'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], shape=(2000, 50)), 'attention_mask': array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]], shape=(2000, 50))}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-tiny')\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return tokenizer(\n",
    "         text.tolist(),\n",
    "         max_length = 50,\n",
    "         truncation = True,\n",
    "         padding = 'max_length',\n",
    "         return_tensors = 'np'\n",
    "    )\n",
    "\n",
    "tokenized = tokenize_text(dataset['review'])\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "352fb046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading a PyTorch model in TensorFlow, requires both PyTorch and TensorFlow to be installed. Please see https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m \u001b[43mTFBertModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprajjwal1/bert-tiny\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m outputs \u001b[38;5;241m=\u001b[39m bert_model(tokenized)\n\u001b[1;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/PhpstormProjects/ai_learn/.venv/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:2943\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_pytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_pytorch_checkpoint_in_tf2_model\n\u001b[1;32m   2942\u001b[0m     \u001b[38;5;66;03m# Load from a PyTorch checkpoint\u001b[39;00m\n\u001b[0;32m-> 2943\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_pytorch_checkpoint_in_tf2_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_missing_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2947\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_loading_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_loading_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2948\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_weight_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf_to_pt_weight_rename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_to_pt_weight_rename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2950\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;66;03m# we might need to extend the variable scope for composite models\u001b[39;00m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_weight_prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/PhpstormProjects/ai_learn/.venv/lib/python3.10/site-packages/transformers/modeling_tf_pytorch_utils.py:181\u001b[0m, in \u001b[0;36mload_pytorch_checkpoint_in_tf2_model\u001b[0;34m(tf_model, pytorch_checkpoint_path, tf_inputs, allow_missing_keys, output_loading_info, _prefix, tf_to_pt_weight_rename)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msafetensors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_file \u001b[38;5;28;01mas\u001b[39;00m safe_load_file  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained('prajjwal1/bert-tiny', from_pt=True)\n",
    "outputs = bert_model(tokenized)\n",
    "\n",
    "X = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "y = dataset['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e25404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_actor_sentiment(text):\n",
    "    doc = spacy_nlp(text)\n",
    "    actor_sentiment = None\n",
    "    for token in doc:\n",
    "        if token.lemma_ == \"actor\" or token.lemma_ == \"actors\" and token.pos_ == \"NOUN\":\n",
    "            for child in token.children:\n",
    "                if child.pos_ == \"ADJ\":\n",
    "                    sentiment = child.text.lower()\n",
    "                    if sentiment in ['good', 'great', 'excellent', 'amazing', 'brilliant', 'fantastic']:\n",
    "                        actor_sentiment = 0\n",
    "                    elif sentiment in ['bad', 'terrible', 'awful', 'poor', 'horrible']:\n",
    "                        actor_sentiment = 1\n",
    "                    break\n",
    "            if actor_sentiment:\n",
    "                break\n",
    "    return actor_sentiment\n",
    "\n",
    "\n",
    "dataset['actor_sentiment'] = dataset['review'].apply(extract_actor_sentiment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_with_actors_sent = dataset[dataset['actor_sentiment'].notna()]\n",
    "dataset_with_actors_sent.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_by_actor = dataset_with_actors_sent.drop('actor_sentiment', axis=1)\n",
    "y_by_actor = dataset_with_actors_sent['actor_sentiment']\n",
    "\n",
    "tokenized = tokenize_text(X_by_actor['review'])\n",
    "outputs_by_actor = bert_model(tokenized)\n",
    "X_by_actor = outputs_by_actor.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "X_train_actor, X_test_actor, y_train_actor, y_test_actor = train_test_split(X_by_actor, y_by_actor, test_size = 0.2)\n",
    "\n",
    "log_reg_by_actor = LogisticRegression(max_iter=1000)\n",
    "log_reg_by_actor.fit(X_train_actor, y_train_actor)\n",
    "y_pred_actor = log_reg_by_actor.predict(X_test_actor)\n",
    "print(classification_report(y_test_actor, y_pred_actor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
